{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a21374b2-2df9-4910-bacf-deeea0ed44ae",
   "metadata": {},
   "source": [
    "# 前処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "becd4020",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a019d9-d1fa-47c3-b1c8-9cb0a37410a3",
   "metadata": {},
   "source": [
    "## 形態素解析\n",
    "\n",
    "spaCyを使うことで形態素解析とトークナイズを行うことができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b961ce-c6bc-43ad-bde9-4cbe1445687a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"ja_core_news_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebdea5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"今日は銀座から池袋へ向かいました。\")\n",
    "list(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd4fd5e-398f-40d7-b839-cf4e8874260f",
   "metadata": {},
   "source": [
    "## 見出し語（レンマ）化\n",
    "\n",
    "`.lemma_` 属性を参照して見出し語化できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22106737-f579-44a3-a3f7-ff7d3327b382",
   "metadata": {},
   "outputs": [],
   "source": [
    "for token in doc:\n",
    "    print(token.text, token.pos_, token.lemma_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93099cbe",
   "metadata": {},
   "source": [
    "## 品詞によるフィルタリング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395f1842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 形態素の品詞の形態について書く (Universal Dependencies)\n",
    "# https://hironsan.hatenablog.com/entry/visualize-dependencies-per-bunsetsu\n",
    "doc = nlp(\"今日は銀座から池袋へ向かいました。\")\n",
    "\n",
    "# 内容語のみを残すようにフィルタリング\n",
    "for token in nlp(doc):\n",
    "    if token.pos_ in {\"NOUN\", \"PROPN\", \"VERB\"}:\n",
    "        print(token.pos_, token.lemma_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a9ff08",
   "metadata": {},
   "source": [
    "## ストップワードによるフィルタリング\n",
    "\n",
    "ストップワードの集合を作成し、トークンがストップワードに含まれていれば出力しないようにします。\n",
    "ストップワードを考慮してトークナイズする関数を定義してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178b779d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text, stopwords=set()):\n",
    "    return [t.lemma_ for t in nlp(text) if t.lemma_ not in stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3b8054",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = {\n",
    "    \"は\", \"から\", \"へ\",\n",
    "    \"ます\", \"た\",\n",
    "    \"。\", \"、\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf99e542",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenize(\"今日は銀座から池袋へ向かいました。\", stopwords=stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2a9d2b-28b2-4e58-b794-7f5f7361373a",
   "metadata": {},
   "source": [
    "## 小文字化\n",
    "\n",
    "strオブジェクトのlowerを使います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ad1746",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"spaCyの練習\")\n",
    "for token in doc:\n",
    "    print(token.text, token.text.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e13fa9-c670-4abf-8b44-de83fdaa6fbb",
   "metadata": {},
   "source": [
    "## 絵文字の変換\n",
    "\n",
    "SNSのデータを処理する際には絵文字が出現することが多いです。\n",
    "絵文字を事前に文字に変換しておくと処理しやすいです。\n",
    "\n",
    "絵文字の変換には[emoji](https://github.com/carpedm20/emoji/)パッケージが便利です。\n",
    "\n",
    "```{note}\n",
    "emojiパッケージを利用するにはインストールが必要です。\n",
    "\n",
    "    pip install emoji==1.7.0\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7afcf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import emoji"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1688a451",
   "metadata": {},
   "source": [
    "絵文字を文字列に変換します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f916ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "emoji.demojize(\"今日はケーキを食べます🍰\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4c93ed",
   "metadata": {},
   "source": [
    "文字列を絵文字に変換します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab50c349",
   "metadata": {},
   "outputs": [],
   "source": [
    "emoji.emojize(\"今日はケーキを食べます:shortcake:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a786340d",
   "metadata": {},
   "source": [
    "絵文字を除去します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53f311f",
   "metadata": {},
   "outputs": [],
   "source": [
    "emoji.replace_emoji(\"今日はケーキを食べます🍰\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
